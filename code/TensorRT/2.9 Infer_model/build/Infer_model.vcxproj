<?xml version="1.0" encoding="utf-8"?>
<Project DefaultTargets="Build" ToolsVersion="16.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <PropertyGroup>
    <PreferredToolArchitecture>x64</PreferredToolArchitecture>
  </PropertyGroup>
  <ItemGroup Label="ProjectConfigurations">
    <ProjectConfiguration Include="Debug|x64">
      <Configuration>Debug</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|x64">
      <Configuration>Release</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="MinSizeRel|x64">
      <Configuration>MinSizeRel</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="RelWithDebInfo|x64">
      <Configuration>RelWithDebInfo</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
  </ItemGroup>
  <PropertyGroup Label="Globals">
    <ProjectGuid>{2264DD32-9884-3CF2-A795-F5A12F6629DF}</ProjectGuid>
    <Keyword>Win32Proj</Keyword>
    <WindowsTargetPlatformVersion>10.0.22000.0</WindowsTargetPlatformVersion>
    <Platform>x64</Platform>
    <ProjectName>Infer_model</ProjectName>
    <VCProjectUpgraderObjectName>NoUpgrade</VCProjectUpgraderObjectName>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <CharacterSet>MultiByte</CharacterSet>
    <PlatformToolset>v142</PlatformToolset>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <CharacterSet>MultiByte</CharacterSet>
    <PlatformToolset>v142</PlatformToolset>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <CharacterSet>MultiByte</CharacterSet>
    <PlatformToolset>v142</PlatformToolset>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <CharacterSet>MultiByte</CharacterSet>
    <PlatformToolset>v142</PlatformToolset>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
  <ImportGroup Label="ExtensionSettings">
    <Import Project="$(VCTargetsPath)\BuildCustomizations\CUDA 12.1.props" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <PropertyGroup Label="UserMacros" />
  <PropertyGroup>
    <_ProjectFileVersion>10.0.20506.1</_ProjectFileVersion>
    <OutDir Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\Debug\</OutDir>
    <IntDir Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Infer_model.dir\Debug\</IntDir>
    <TargetName Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Infer_model</TargetName>
    <TargetExt Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">.exe</TargetExt>
    <LinkIncremental Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">true</LinkIncremental>
    <GenerateManifest Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">true</GenerateManifest>
    <OutDir Condition="'$(Configuration)|$(Platform)'=='Release|x64'">C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\Release\</OutDir>
    <IntDir Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Infer_model.dir\Release\</IntDir>
    <TargetName Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Infer_model</TargetName>
    <TargetExt Condition="'$(Configuration)|$(Platform)'=='Release|x64'">.exe</TargetExt>
    <LinkIncremental Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkIncremental>
    <GenerateManifest Condition="'$(Configuration)|$(Platform)'=='Release|x64'">true</GenerateManifest>
    <OutDir Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\MinSizeRel\</OutDir>
    <IntDir Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Infer_model.dir\MinSizeRel\</IntDir>
    <TargetName Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Infer_model</TargetName>
    <TargetExt Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">.exe</TargetExt>
    <LinkIncremental Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkIncremental>
    <GenerateManifest Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">true</GenerateManifest>
    <OutDir Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\RelWithDebInfo\</OutDir>
    <IntDir Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Infer_model.dir\RelWithDebInfo\</IntDir>
    <TargetName Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Infer_model</TargetName>
    <TargetExt Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">.exe</TargetExt>
    <LinkIncremental Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">true</LinkIncremental>
    <GenerateManifest Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">true</GenerateManifest>
  </PropertyGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <ClCompile>
      <AdditionalIncludeDirectories>C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\inc;E:\opencv;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\include;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\common;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\utils;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <AssemblerListingLocation>$(IntDir)</AssemblerListingLocation>
      <BasicRuntimeChecks>EnableFastChecks</BasicRuntimeChecks>
      <DebugInformationFormat>ProgramDatabase</DebugInformationFormat>
      <ExceptionHandling>Sync</ExceptionHandling>
      <InlineFunctionExpansion>Disabled</InlineFunctionExpansion>
      <LanguageStandard>stdcpp17</LanguageStandard>
      <Optimization>Disabled</Optimization>
      <PrecompiledHeader>NotUsing</PrecompiledHeader>
      <RuntimeLibrary>MultiThreadedDebugDLL</RuntimeLibrary>
      <RuntimeTypeInfo>true</RuntimeTypeInfo>
      <UseFullPaths>false</UseFullPaths>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;WIN32 /D_WINDOWS /GR /EHsc;CMAKE_INTDIR="Debug"</PreprocessorDefinitions>
      <ObjectFileName>$(IntDir)</ObjectFileName>
      <ScanSourceForModuleDependencies>false</ScanSourceForModuleDependencies>
    </ClCompile>
    <ResourceCompile>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_DEBUG;_WINDOWS;WIN32 /D_WINDOWS /GR /EHsc;CMAKE_INTDIR=\"Debug\"</PreprocessorDefinitions>
      <AdditionalIncludeDirectories>C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\inc;E:\opencv;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\include;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\common;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\utils;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
    </ResourceCompile>
    <Midl>
      <AdditionalIncludeDirectories>C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\inc;E:\opencv;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\include;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\common;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\utils;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <OutputDirectory>$(ProjectDir)/$(IntDir)</OutputDirectory>
      <HeaderFileName>%(Filename).h</HeaderFileName>
      <TypeLibraryName>%(Filename).tlb</TypeLibraryName>
      <InterfaceIdentifierFileName>%(Filename)_i.c</InterfaceIdentifierFileName>
      <ProxyFileName>%(Filename)_p.c</ProxyFileName>
    </Midl>
    <Link>
      <AdditionalDependencies>cudart.lib;cublas.lib;cudnn.lib;nvinfer_10.lib;nvonnxparser_10.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;comdlg32.lib;advapi32.lib</AdditionalDependencies>
      <AdditionalLibraryDirectories>C:/Program Files/NVIDIA GPU Computing Toolkit/TensorRT-10.1.0.27/lib;C:/Program Files/NVIDIA GPU Computing Toolkit/TensorRT-10.1.0.27/lib/$(Configuration);/lib64;/lib64/$(Configuration);%(AdditionalLibraryDirectories)</AdditionalLibraryDirectories>
      <AdditionalOptions>%(AdditionalOptions) /machine:x64</AdditionalOptions>
      <GenerateDebugInformation>true</GenerateDebugInformation>
      <IgnoreSpecificDefaultLibraries>%(IgnoreSpecificDefaultLibraries)</IgnoreSpecificDefaultLibraries>
      <ImportLibrary>C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build/Debug/Infer_model.lib</ImportLibrary>
      <ProgramDataBaseFile>C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build/Debug/Infer_model.pdb</ProgramDataBaseFile>
      <SubSystem>Console</SubSystem>
    </Link>
    <ProjectReference>
      <LinkLibraryDependencies>false</LinkLibraryDependencies>
    </ProjectReference>
    <CudaLink>
      <AdditionalOptions>-forward-unknown-to-host-compiler -Wno-deprecated-gpu-targets </AdditionalOptions>
      <PerformDeviceLink>false</PerformDeviceLink>
    </CudaLink>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <ClCompile>
      <AdditionalIncludeDirectories>C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\inc;E:\opencv;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\include;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\common;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\utils;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <AdditionalOptions>%(AdditionalOptions) -O3 -w</AdditionalOptions>
      <AssemblerListingLocation>$(IntDir)</AssemblerListingLocation>
      <ExceptionHandling>Sync</ExceptionHandling>
      <LanguageStandard>stdcpp17</LanguageStandard>
      <PrecompiledHeader>NotUsing</PrecompiledHeader>
      <RuntimeLibrary>MultiThreadedDLL</RuntimeLibrary>
      <RuntimeTypeInfo>true</RuntimeTypeInfo>
      <UseFullPaths>false</UseFullPaths>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;WIN32 /D_WINDOWS /GR /EHsc;CMAKE_INTDIR="Release"</PreprocessorDefinitions>
      <ObjectFileName>$(IntDir)</ObjectFileName>
      <DebugInformationFormat>
      </DebugInformationFormat>
      <ScanSourceForModuleDependencies>false</ScanSourceForModuleDependencies>
    </ClCompile>
    <ResourceCompile>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;WIN32 /D_WINDOWS /GR /EHsc;CMAKE_INTDIR=\"Release\"</PreprocessorDefinitions>
      <AdditionalIncludeDirectories>C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\inc;E:\opencv;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\include;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\common;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\utils;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
    </ResourceCompile>
    <Midl>
      <AdditionalIncludeDirectories>C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\inc;E:\opencv;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\include;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\common;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\utils;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <OutputDirectory>$(ProjectDir)/$(IntDir)</OutputDirectory>
      <HeaderFileName>%(Filename).h</HeaderFileName>
      <TypeLibraryName>%(Filename).tlb</TypeLibraryName>
      <InterfaceIdentifierFileName>%(Filename)_i.c</InterfaceIdentifierFileName>
      <ProxyFileName>%(Filename)_p.c</ProxyFileName>
    </Midl>
    <Link>
      <AdditionalDependencies>cudart.lib;cublas.lib;cudnn.lib;nvinfer_10.lib;nvonnxparser_10.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;comdlg32.lib;advapi32.lib</AdditionalDependencies>
      <AdditionalLibraryDirectories>C:/Program Files/NVIDIA GPU Computing Toolkit/TensorRT-10.1.0.27/lib;C:/Program Files/NVIDIA GPU Computing Toolkit/TensorRT-10.1.0.27/lib/$(Configuration);/lib64;/lib64/$(Configuration);%(AdditionalLibraryDirectories)</AdditionalLibraryDirectories>
      <AdditionalOptions>%(AdditionalOptions) /machine:x64</AdditionalOptions>
      <GenerateDebugInformation>false</GenerateDebugInformation>
      <IgnoreSpecificDefaultLibraries>%(IgnoreSpecificDefaultLibraries)</IgnoreSpecificDefaultLibraries>
      <ImportLibrary>C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build/Release/Infer_model.lib</ImportLibrary>
      <ProgramDataBaseFile>C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build/Release/Infer_model.pdb</ProgramDataBaseFile>
      <SubSystem>Console</SubSystem>
    </Link>
    <ProjectReference>
      <LinkLibraryDependencies>false</LinkLibraryDependencies>
    </ProjectReference>
    <CudaLink>
      <AdditionalOptions>-forward-unknown-to-host-compiler -Wno-deprecated-gpu-targets </AdditionalOptions>
      <PerformDeviceLink>false</PerformDeviceLink>
    </CudaLink>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">
    <ClCompile>
      <AdditionalIncludeDirectories>C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\inc;E:\opencv;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\include;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\common;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\utils;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <AssemblerListingLocation>$(IntDir)</AssemblerListingLocation>
      <ExceptionHandling>Sync</ExceptionHandling>
      <InlineFunctionExpansion>OnlyExplicitInline</InlineFunctionExpansion>
      <LanguageStandard>stdcpp17</LanguageStandard>
      <Optimization>MinSpace</Optimization>
      <PrecompiledHeader>NotUsing</PrecompiledHeader>
      <RuntimeLibrary>MultiThreadedDLL</RuntimeLibrary>
      <RuntimeTypeInfo>true</RuntimeTypeInfo>
      <UseFullPaths>false</UseFullPaths>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;NDEBUG;WIN32 /D_WINDOWS /GR /EHsc;CMAKE_INTDIR="MinSizeRel"</PreprocessorDefinitions>
      <ObjectFileName>$(IntDir)</ObjectFileName>
      <DebugInformationFormat>
      </DebugInformationFormat>
      <ScanSourceForModuleDependencies>false</ScanSourceForModuleDependencies>
    </ClCompile>
    <ResourceCompile>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;NDEBUG;WIN32 /D_WINDOWS /GR /EHsc;CMAKE_INTDIR=\"MinSizeRel\"</PreprocessorDefinitions>
      <AdditionalIncludeDirectories>C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\inc;E:\opencv;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\include;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\common;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\utils;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
    </ResourceCompile>
    <Midl>
      <AdditionalIncludeDirectories>C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\inc;E:\opencv;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\include;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\common;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\utils;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <OutputDirectory>$(ProjectDir)/$(IntDir)</OutputDirectory>
      <HeaderFileName>%(Filename).h</HeaderFileName>
      <TypeLibraryName>%(Filename).tlb</TypeLibraryName>
      <InterfaceIdentifierFileName>%(Filename)_i.c</InterfaceIdentifierFileName>
      <ProxyFileName>%(Filename)_p.c</ProxyFileName>
    </Midl>
    <Link>
      <AdditionalDependencies>cudart.lib;cublas.lib;cudnn.lib;nvinfer_10.lib;nvonnxparser_10.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;comdlg32.lib;advapi32.lib</AdditionalDependencies>
      <AdditionalLibraryDirectories>C:/Program Files/NVIDIA GPU Computing Toolkit/TensorRT-10.1.0.27/lib;C:/Program Files/NVIDIA GPU Computing Toolkit/TensorRT-10.1.0.27/lib/$(Configuration);/lib64;/lib64/$(Configuration);%(AdditionalLibraryDirectories)</AdditionalLibraryDirectories>
      <AdditionalOptions>%(AdditionalOptions) /machine:x64</AdditionalOptions>
      <GenerateDebugInformation>false</GenerateDebugInformation>
      <IgnoreSpecificDefaultLibraries>%(IgnoreSpecificDefaultLibraries)</IgnoreSpecificDefaultLibraries>
      <ImportLibrary>C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build/MinSizeRel/Infer_model.lib</ImportLibrary>
      <ProgramDataBaseFile>C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build/MinSizeRel/Infer_model.pdb</ProgramDataBaseFile>
      <SubSystem>Console</SubSystem>
    </Link>
    <ProjectReference>
      <LinkLibraryDependencies>false</LinkLibraryDependencies>
    </ProjectReference>
    <CudaLink>
      <AdditionalOptions>-forward-unknown-to-host-compiler -Wno-deprecated-gpu-targets </AdditionalOptions>
      <PerformDeviceLink>false</PerformDeviceLink>
    </CudaLink>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">
    <ClCompile>
      <AdditionalIncludeDirectories>C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\inc;E:\opencv;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\include;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\common;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\utils;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <AssemblerListingLocation>$(IntDir)</AssemblerListingLocation>
      <DebugInformationFormat>ProgramDatabase</DebugInformationFormat>
      <ExceptionHandling>Sync</ExceptionHandling>
      <InlineFunctionExpansion>OnlyExplicitInline</InlineFunctionExpansion>
      <LanguageStandard>stdcpp17</LanguageStandard>
      <Optimization>MaxSpeed</Optimization>
      <PrecompiledHeader>NotUsing</PrecompiledHeader>
      <RuntimeLibrary>MultiThreadedDLL</RuntimeLibrary>
      <RuntimeTypeInfo>true</RuntimeTypeInfo>
      <UseFullPaths>false</UseFullPaths>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;NDEBUG;WIN32 /D_WINDOWS /GR /EHsc;CMAKE_INTDIR="RelWithDebInfo"</PreprocessorDefinitions>
      <ObjectFileName>$(IntDir)</ObjectFileName>
      <ScanSourceForModuleDependencies>false</ScanSourceForModuleDependencies>
    </ClCompile>
    <ResourceCompile>
      <PreprocessorDefinitions>%(PreprocessorDefinitions);WIN32;_WINDOWS;NDEBUG;WIN32 /D_WINDOWS /GR /EHsc;CMAKE_INTDIR=\"RelWithDebInfo\"</PreprocessorDefinitions>
      <AdditionalIncludeDirectories>C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\inc;E:\opencv;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\include;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\common;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\utils;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
    </ResourceCompile>
    <Midl>
      <AdditionalIncludeDirectories>C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\inc;E:\opencv;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\include;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\common;C:\Program Files\NVIDIA GPU Computing Toolkit\TensorRT-10.1.0.27\samples\utils;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
      <OutputDirectory>$(ProjectDir)/$(IntDir)</OutputDirectory>
      <HeaderFileName>%(Filename).h</HeaderFileName>
      <TypeLibraryName>%(Filename).tlb</TypeLibraryName>
      <InterfaceIdentifierFileName>%(Filename)_i.c</InterfaceIdentifierFileName>
      <ProxyFileName>%(Filename)_p.c</ProxyFileName>
    </Midl>
    <Link>
      <AdditionalDependencies>cudart.lib;cublas.lib;cudnn.lib;nvinfer_10.lib;nvonnxparser_10.lib;kernel32.lib;user32.lib;gdi32.lib;winspool.lib;shell32.lib;ole32.lib;oleaut32.lib;uuid.lib;comdlg32.lib;advapi32.lib</AdditionalDependencies>
      <AdditionalLibraryDirectories>C:/Program Files/NVIDIA GPU Computing Toolkit/TensorRT-10.1.0.27/lib;C:/Program Files/NVIDIA GPU Computing Toolkit/TensorRT-10.1.0.27/lib/$(Configuration);/lib64;/lib64/$(Configuration);%(AdditionalLibraryDirectories)</AdditionalLibraryDirectories>
      <AdditionalOptions>%(AdditionalOptions) /machine:x64</AdditionalOptions>
      <GenerateDebugInformation>true</GenerateDebugInformation>
      <IgnoreSpecificDefaultLibraries>%(IgnoreSpecificDefaultLibraries)</IgnoreSpecificDefaultLibraries>
      <ImportLibrary>C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build/RelWithDebInfo/Infer_model.lib</ImportLibrary>
      <ProgramDataBaseFile>C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build/RelWithDebInfo/Infer_model.pdb</ProgramDataBaseFile>
      <SubSystem>Console</SubSystem>
    </Link>
    <ProjectReference>
      <LinkLibraryDependencies>false</LinkLibraryDependencies>
    </ProjectReference>
    <CudaLink>
      <AdditionalOptions>-forward-unknown-to-host-compiler -Wno-deprecated-gpu-targets </AdditionalOptions>
      <PerformDeviceLink>false</PerformDeviceLink>
    </CudaLink>
  </ItemDefinitionGroup>
  <ItemGroup>
    <CustomBuild Include="C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\CMakeLists.txt">
      <UseUtf8Encoding>Always</UseUtf8Encoding>
      <Message Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Building Custom Rule C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/CMakeLists.txt</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" "-SC:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model" "-BC:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build" --check-stamp-file "C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build/CMakeFiles/generate.stamp"
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeCUDAInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeCXXInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeCommonLanguageInclude.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeGenericSystem.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeInitializeConfigs.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeLanguageInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeRCInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeSystemSpecificInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeSystemSpecificInitialize.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\CMakeCommonCompilerMacros.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\MSVC-CXX.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\MSVC.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\NVIDIA-CUDA.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\NVIDIA.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\FindCUDAToolkit.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\FindPackageHandleStandardArgs.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\FindPackageMessage.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-Initialize.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-MSVC-CXX.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-MSVC.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-NVIDIA-CUDA.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\WindowsPaths.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeCUDACompiler.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeCXXCompiler.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeRCCompiler.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeSystem.cmake;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\generate.stamp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Building Custom Rule C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/CMakeLists.txt</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='Release|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" "-SC:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model" "-BC:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build" --check-stamp-file "C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build/CMakeFiles/generate.stamp"
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeCUDAInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeCXXInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeCommonLanguageInclude.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeGenericSystem.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeInitializeConfigs.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeLanguageInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeRCInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeSystemSpecificInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeSystemSpecificInitialize.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\CMakeCommonCompilerMacros.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\MSVC-CXX.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\MSVC.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\NVIDIA-CUDA.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\NVIDIA.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\FindCUDAToolkit.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\FindPackageHandleStandardArgs.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\FindPackageMessage.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-Initialize.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-MSVC-CXX.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-MSVC.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-NVIDIA-CUDA.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\WindowsPaths.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeCUDACompiler.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeCXXCompiler.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeRCCompiler.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeSystem.cmake;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='Release|x64'">C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\generate.stamp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='Release|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">Building Custom Rule C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/CMakeLists.txt</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" "-SC:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model" "-BC:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build" --check-stamp-file "C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build/CMakeFiles/generate.stamp"
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeCUDAInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeCXXInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeCommonLanguageInclude.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeGenericSystem.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeInitializeConfigs.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeLanguageInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeRCInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeSystemSpecificInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeSystemSpecificInitialize.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\CMakeCommonCompilerMacros.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\MSVC-CXX.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\MSVC.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\NVIDIA-CUDA.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\NVIDIA.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\FindCUDAToolkit.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\FindPackageHandleStandardArgs.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\FindPackageMessage.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-Initialize.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-MSVC-CXX.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-MSVC.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-NVIDIA-CUDA.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\WindowsPaths.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeCUDACompiler.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeCXXCompiler.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeRCCompiler.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeSystem.cmake;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\generate.stamp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='MinSizeRel|x64'">false</LinkObjects>
      <Message Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">Building Custom Rule C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/CMakeLists.txt</Message>
      <Command Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">setlocal
"C:\Program Files\CMake\bin\cmake.exe" "-SC:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model" "-BC:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build" --check-stamp-file "C:/Users/22681/Desktop/project/cudalearn/notes/code/TensorRT/2.9 Infer_model/build/CMakeFiles/generate.stamp"
if %errorlevel% neq 0 goto :cmEnd
:cmEnd
endlocal &amp; call :cmErrorLevel %errorlevel% &amp; goto :cmDone
:cmErrorLevel
exit /b %1
:cmDone
if %errorlevel% neq 0 goto :VCEnd</Command>
      <AdditionalInputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeCUDAInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeCXXInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeCommonLanguageInclude.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeGenericSystem.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeInitializeConfigs.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeLanguageInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeRCInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeSystemSpecificInformation.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\CMakeSystemSpecificInitialize.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\CMakeCommonCompilerMacros.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\MSVC-CXX.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\MSVC.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\NVIDIA-CUDA.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Compiler\NVIDIA.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\FindCUDAToolkit.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\FindPackageHandleStandardArgs.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\FindPackageMessage.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-Initialize.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-MSVC-CXX.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-MSVC.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows-NVIDIA-CUDA.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\Windows.cmake;C:\Program Files\CMake\share\cmake-3.29\Modules\Platform\WindowsPaths.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeCUDACompiler.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeCXXCompiler.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeRCCompiler.cmake;C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\3.29.3\CMakeSystem.cmake;%(AdditionalInputs)</AdditionalInputs>
      <Outputs Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\CMakeFiles\generate.stamp</Outputs>
      <LinkObjects Condition="'$(Configuration)|$(Platform)'=='RelWithDebInfo|x64'">false</LinkObjects>
    </CustomBuild>
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src\main.cpp" />
    <ClCompile Include="C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src\model.cpp" />
    <ClCompile Include="C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\src\utils.cpp" />
  </ItemGroup>
  <ItemGroup>
    <ProjectReference Include="C:\Users\22681\Desktop\project\cudalearn\notes\code\TensorRT\2.9 Infer_model\build\ZERO_CHECK.vcxproj">
      <Project>{9CCC5515-1D9B-3017-9745-EEA79E15E2D1}</Project>
      <Name>ZERO_CHECK</Name>
      <ReferenceOutputAssembly>false</ReferenceOutputAssembly>
      <CopyToOutputDirectory>Never</CopyToOutputDirectory>
    </ProjectReference>
  </ItemGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
  <ImportGroup Label="ExtensionTargets">
    <Import Project="$(VCTargetsPath)\BuildCustomizations\CUDA 12.1.targets" />
  </ImportGroup>
</Project>